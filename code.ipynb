{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "6c72bae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/Shenyiyang/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/Shenyiyang/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/Shenyiyang/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import string\n",
    "import nltk\n",
    "import textblob\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from textblob import TextBlob\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.semi_supervised import SelfTrainingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea341417",
   "metadata": {},
   "source": [
    "<font size=5 > Read data </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "7d0d91b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw_full = pd.read_pickle('train.pkl')\n",
    "train_raw_text = train_raw_full['text']\n",
    "\n",
    "train_emb_full = pd.read_pickle('train_emb.pkl')\n",
    "train_emb = pd.DataFrame(train_emb_full.TFIDF.to_list())\n",
    "train_emb_label = train_emb_full['Sentiment']\n",
    "\n",
    "dev_raw = pd.read_pickle('dev.pkl')\n",
    "dev_raw_text = dev_raw['text']\n",
    "\n",
    "dev_emb_full = pd.read_pickle('dev_emb.pkl')\n",
    "dev_emb = pd.DataFrame(dev_emb_full.TFIDF.to_list())\n",
    "dev_emb_label = dev_emb_full['Sentiment']\n",
    "\n",
    "test_raw_full = pd.read_pickle('test.pkl')\n",
    "test_raw_text = test_raw_full['text']\n",
    "\n",
    "test_emb_full = pd.read_pickle('test_emb.pkl')\n",
    "test_emb = pd.DataFrame(test_emb_full.TFIDF.to_list())\n",
    "\n",
    "unlabel_raw_full = pd.read_pickle('unlabeled.pkl')\n",
    "unlabel_raw_text = unlabel_raw_full['text']\n",
    "\n",
    "unlabel_emb_full = pd.read_pickle('unlabeled_emb.pkl')\n",
    "unlabel_emb = pd.DataFrame(unlabel_emb_full.TFIDF.to_list())\n",
    "unlabel_emb_label = unlabel_emb_full['Sentiment']\n",
    "\n",
    "# train_raw_text\n",
    "# train_emb\n",
    "# unlabel_emb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083b7fed",
   "metadata": {},
   "source": [
    "<font size=5 > Feature Engineering </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2f1e72d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                  whats school these days\n",
       "1        so he got in some trouble and him and his fagg...\n",
       "2                 happy gilmore is the greatest movie ever\n",
       "3        a day like this and my dad cancels netflix why...\n",
       "4        its so dead at work  i shouldnt even have to b...\n",
       "                               ...                        \n",
       "99995              thats prolly who stole my fuckn mk belt\n",
       "99996    getting my car services without my dad or  is ...\n",
       "99997                                               nf  fb\n",
       "99998    kinley is having a milk watching the race that...\n",
       "99999    i swear one day me and  will do the red nose t...\n",
       "Name: text, Length: 100000, dtype: object"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature Engineering\n",
    "\n",
    "def process_text(text):\n",
    "    \n",
    "#      remove _TWITTER-ENTITY_\n",
    "    text = re.sub(r'_TWITTER-ENTITY_', '', text)\n",
    "    \n",
    "#     remove any url\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags = re.MULTILINE)\n",
    "    \n",
    "#     remove symbols\n",
    "    text = re.sub(r'\\@\\w+|\\#', '', text)\n",
    "      \n",
    "#     remove punctuations\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "#     transfer text to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    return text\n",
    "    \n",
    "    \n",
    "train_raw_text = train_raw_text.apply(process_text)\n",
    "\n",
    "# train_raw_text\n",
    "\n",
    "dev_raw_text = dev_raw_text.apply(process_text)\n",
    "\n",
    "# dev_raw_text\n",
    "\n",
    "test_raw_text = test_raw_text.apply(process_text)\n",
    "# test_raw_text\n",
    "\n",
    "unlabel_raw_text = unlabel_raw_text.apply(process_text)\n",
    "# unlabel_raw_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "66f4e494",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what school day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>got troubl faggot friend cri babi band made song</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>happi gilmor great movi ever</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>day like dad cancel netflix whyyyy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dead work shouldnt even</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>that prolli stole fuckn mk belt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>get car servic without dad terrifi idk saywhatnow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>nf fb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>kinley milk watch race that best commerci ever...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>swear one day red nose togeth lmao</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text\n",
       "0                                        what school day\n",
       "1       got troubl faggot friend cri babi band made song\n",
       "2                           happi gilmor great movi ever\n",
       "3                     day like dad cancel netflix whyyyy\n",
       "4                                dead work shouldnt even\n",
       "...                                                  ...\n",
       "99995                    that prolli stole fuckn mk belt\n",
       "99996  get car servic without dad terrifi idk saywhatnow\n",
       "99997                                              nf fb\n",
       "99998  kinley milk watch race that best commerci ever...\n",
       "99999                 swear one day red nose togeth lmao\n",
       "\n",
       "[100000 rows x 1 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "\n",
    "train_raw_text_nostopwords = train_raw_text.str.split()\n",
    "train_raw_text_nostopwords = train_raw_text_nostopwords.apply(lambda x: [word for word in x if word not in (stop_words)])\n",
    "\n",
    "dev_raw_text_nostopwords = dev_raw_text.str.split()\n",
    "dev_raw_text_nostopwords = dev_raw_text_nostopwords.apply(lambda x: [word for word in x if word not in (stop_words)])\n",
    "\n",
    "test_raw_text_nostopwords = test_raw_text.str.split()\n",
    "test_raw_text_nostopwords = test_raw_text_nostopwords.apply(lambda x: [word for word in x if word not in (stop_words)])\n",
    "\n",
    "unlabel_raw_text_nostopwords = unlabel_raw_text.str.split()\n",
    "unlabel_raw_text_nostopwords = unlabel_raw_text_nostopwords.apply(lambda x: [word for word in x if word not in (stop_words)])\n",
    "\n",
    "\n",
    "# strmming\n",
    "ps = PorterStemmer()\n",
    "\n",
    "train_raw_text_stem = train_raw_text_nostopwords.apply(lambda x: [ps.stem(t) for t in x])\n",
    "\n",
    "dev_raw_text_stem = dev_raw_text_nostopwords.apply(lambda x: [ps.stem(t) for t in x])\n",
    "\n",
    "test_raw_text_stem = test_raw_text_nostopwords.apply(lambda x: [ps.stem(t) for t in x])\n",
    "\n",
    "unlabel_raw_text_stem = unlabel_raw_text_nostopwords.apply(lambda x: [ps.stem(t) for t in x])\n",
    "\n",
    "\n",
    "# lemmatizer\n",
    "lemm = WordNetLemmatizer()\n",
    "\n",
    "train_raw_text_final = train_raw_text_stem.apply(lambda x: [lemm.lemmatize(t, pos = 'a') for t in x])\n",
    "train_text_final = train_raw_text_final.apply(', '.join)\n",
    "train_text_final = train_text_final.replace(',','', regex = True)\n",
    "train_text_final = train_text_final.to_frame()\n",
    "\n",
    "dev_raw_text_final = dev_raw_text_stem.apply(lambda x: [lemm.lemmatize(t, pos = 'a') for t in x])\n",
    "dev_raw_text_final = dev_raw_text_final.apply(', '.join)\n",
    "dev_raw_text_final = dev_raw_text_final.replace(',','', regex = True)\n",
    "dev_raw_text_final = dev_raw_text_final.to_frame()\n",
    "\n",
    "test_raw_text_final = test_raw_text_stem.apply(lambda x: [lemm.lemmatize(t, pos = 'a') for t in x])\n",
    "test_raw_text_final = test_raw_text_final.apply(', '.join)\n",
    "test_raw_text_final = test_raw_text_final.replace(',','', regex = True)\n",
    "test_raw_text_final = test_raw_text_final.to_frame()\n",
    "\n",
    "unlabel_raw_text_final = unlabel_raw_text_stem.apply(lambda x: [lemm.lemmatize(t, pos = 'a') for t in x])\n",
    "unlabel_raw_text_final = unlabel_raw_text_final.apply(', '.join)\n",
    "unlabel_raw_text_final = unlabel_raw_text_final.replace(',','', regex = True)\n",
    "unlabel_raw_text_final = unlabel_raw_text_final.to_frame()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "31083902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function to get the subjectivity\n",
    "def getSubjectivity(text):\n",
    "    return TextBlob(text).sentiment.subjectivity\n",
    "\n",
    "# create function to get the polarity\n",
    "def getPolarity(text):\n",
    "    return TextBlob(text).sentiment.polarity\n",
    "\n",
    "df_train_text_sp = pd.DataFrame()\n",
    "df_train_text_sp['subjectivity'] = train_text_final['text'].apply(getSubjectivity)\n",
    "df_train_text_sp['polarity'] = train_text_final['text'].apply(getPolarity)\n",
    "\n",
    "# append the vlaue to the feature of train_emb dataset\n",
    "train_emb['384'] = df_train_text_sp['subjectivity']\n",
    "train_emb['385'] = df_train_text_sp['polarity']\n",
    "\n",
    "\n",
    "df_dev_text_sp = pd.DataFrame()\n",
    "df_dev_text_sp['subjectivity'] = dev_raw_text_final['text'].apply(getSubjectivity)\n",
    "df_dev_text_sp['polarity'] = dev_raw_text_final['text'].apply(getPolarity)\n",
    "\n",
    "dev_emb['384'] = df_dev_text_sp['subjectivity']\n",
    "dev_emb['385'] = df_dev_text_sp['polarity']\n",
    "\n",
    "\n",
    "df_test_text_sp = pd.DataFrame()\n",
    "df_test_text_sp['subjectivity'] = test_raw_text_final['text'].apply(getSubjectivity)\n",
    "df_test_text_sp['polarity'] = test_raw_text_final['text'].apply(getPolarity)\n",
    "\n",
    "test_emb['384'] = df_test_text_sp['subjectivity']\n",
    "test_emb['385'] = df_test_text_sp['polarity']\n",
    "\n",
    "\n",
    "df_unlabel_text_sp = pd.DataFrame()\n",
    "df_unlabel_text_sp['subjectivity'] = unlabel_raw_text_final['text'].apply(getSubjectivity)\n",
    "df_unlabel_text_sp['polarity'] = unlabel_raw_text_final['text'].apply(getPolarity)\n",
    "\n",
    "unlabel_emb['384'] = df_unlabel_text_sp['subjectivity']\n",
    "unlabel_emb['385'] = df_unlabel_text_sp['polarity']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d1455f",
   "metadata": {},
   "source": [
    "<font size=5 > Models and Evaluation</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "837f8b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base model Accuracy result: 0.61525\n",
      "---------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.70      0.60      0.65      2339\n",
      "    positive       0.53      0.64      0.58      1661\n",
      "\n",
      "    accuracy                           0.62      4000\n",
      "   macro avg       0.62      0.62      0.61      4000\n",
      "weighted avg       0.63      0.62      0.62      4000\n",
      "\n",
      "---------------------------------------------------------------------------------\n",
      "logistic Regression Accuracy result: 0.6995\n",
      "---------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.68      0.71      0.69      1922\n",
      "    positive       0.72      0.69      0.71      2078\n",
      "\n",
      "    accuracy                           0.70      4000\n",
      "   macro avg       0.70      0.70      0.70      4000\n",
      "weighted avg       0.70      0.70      0.70      4000\n",
      "\n",
      "---------------------------------------------------------------------------------\n",
      "Single Tree Accuracy score:0.57475\n",
      "---------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.59      0.57      0.58      2043\n",
      "    positive       0.56      0.58      0.57      1957\n",
      "\n",
      "    accuracy                           0.57      4000\n",
      "   macro avg       0.57      0.57      0.57      4000\n",
      "weighted avg       0.57      0.57      0.57      4000\n",
      "\n",
      "---------------------------------------------------------------------------------\n",
      "Random Forest Accuracy score:0.6695\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.66      0.67      0.67      1952\n",
      "    positive       0.68      0.67      0.67      2048\n",
      "\n",
      "    accuracy                           0.67      4000\n",
      "   macro avg       0.67      0.67      0.67      4000\n",
      "weighted avg       0.67      0.67      0.67      4000\n",
      "\n",
      "---------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# baseline model\n",
    "\n",
    "GaussianNB_model = GaussianNB()\n",
    "GaussianNB_model.fit(train_emb, train_emb_label)\n",
    "GaussianNB_predict = GaussianNB_model.predict(dev_emb)\n",
    "\n",
    "acc_score = accuracy_score(GaussianNB_predict, dev_emb_label)\n",
    "\n",
    "print('Base model Accuracy result:', acc_score)\n",
    "print('---------------------------------------------------------------------------------')\n",
    "print(classification_report(GaussianNB_predict, dev_emb_label))\n",
    "print('---------------------------------------------------------------------------------')\n",
    "\n",
    "# logistic Regression model\n",
    "\n",
    "LR_model = LogisticRegression()\n",
    "LR_model.fit(train_emb, train_emb_label)\n",
    "LR_predict = LR_model.predict(dev_emb)\n",
    "\n",
    "LR_acc_score = accuracy_score(LR_predict, dev_emb_label)\n",
    "\n",
    "print('logistic Regression Accuracy result:', LR_acc_score)\n",
    "print('---------------------------------------------------------------------------------')\n",
    "print(classification_report(LR_predict, dev_emb_label))\n",
    "print('---------------------------------------------------------------------------------')\n",
    "\n",
    "# Radom Forest and Decision Tree\n",
    "\n",
    "dtc_model = DecisionTreeClassifier(random_state=0)\n",
    "rfc_model = RandomForestClassifier(random_state=0)\n",
    "dtc = dtc_model.fit(train_emb, train_emb_label)\n",
    "rfc = rfc_model.fit(train_emb, train_emb_label)\n",
    "dtc_predict = dtc_model.predict(dev_emb)\n",
    "rfc_predict = rfc_model.predict(dev_emb)\n",
    "\n",
    "dtc_score = dtc.score(dev_emb, dev_emb_label)\n",
    "rfc_score = rfc.score(dev_emb, dev_emb_label)\n",
    "\n",
    "print(\"Single Tree Accuracy score:{}\".format(dtc_score))\n",
    "print('---------------------------------------------------------------------------------')\n",
    "print(classification_report(dtc_predict, dev_emb_label))\n",
    "print('---------------------------------------------------------------------------------')\n",
    "print(\"Random Forest Accuracy score:{}\".format(rfc_score))\n",
    "print(classification_report(rfc_predict, dev_emb_label))\n",
    "print('---------------------------------------------------------------------------------')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75d4ff5",
   "metadata": {},
   "source": [
    "<font size=5 > Improve Models </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6abb7fd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1, 'class_weight': 'balanced', 'max_iter': 10, 'solver': 'lbfgs'}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adjust parameters\n",
    "\n",
    "params = {'C':[0.0001, 1, 100, 1000],\n",
    "          'max_iter':[1, 10, 100, 500],\n",
    "          'class_weight':['balanced', None],\n",
    "          'solver':['liblinear','sag','lbfgs','newton-cg']\n",
    "         }\n",
    "lr = LogisticRegression()\n",
    "clf = GridSearchCV(lr, param_grid=params, cv=10)\n",
    "clf.fit(dev_emb, dev_emb_label)\n",
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "50b3e175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_lr = LogisticRegression(**clf.best_params_)\n",
    "# new_lr.fit(train_emb, train_emb_label)\n",
    "# new_predict = new_lr.predict(dev_emb)\n",
    "# new_acc_score = accuracy_score(dev_emb_label, new_predict)\n",
    "# print('new logistic Regression Accuracy result:', new_acc_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b933ac44",
   "metadata": {},
   "source": [
    "<font size=5 > semi-supervised learning </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "e3107f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semi-supervised Accuracy result: 0.70175\n",
      "---------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.71      0.69      1877\n",
      "    positive       0.73      0.69      0.71      2123\n",
      "\n",
      "    accuracy                           0.70      4000\n",
      "   macro avg       0.70      0.70      0.70      4000\n",
      "weighted avg       0.70      0.70      0.70      4000\n",
      "\n",
      "---------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "semi_train_emb = pd.concat([train_emb, unlabel_emb]).reset_index(drop = True)\n",
    "replace_label = pd.Series([-1]*100000)\n",
    "semi_train_emb_label = pd.concat([train_emb_label, replace_label]).reset_index(drop = True)\n",
    "\n",
    "new_lr = LogisticRegression()\n",
    "semi_model = SelfTrainingClassifier(new_lr, threshold = 0.6)\n",
    "semi_model.fit(semi_train_emb, semi_train_emb_label)\n",
    "semi_predict = semi_model.predict(dev_emb)\n",
    "\n",
    "semi_acc_score = accuracy_score(semi_predict, dev_emb_label)\n",
    "\n",
    "print('Semi-supervised Accuracy result:', semi_acc_score)\n",
    "print('---------------------------------------------------------------------------------')\n",
    "print(classification_report(semi_predict, dev_emb_label))\n",
    "print('---------------------------------------------------------------------------------')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2bb32d0",
   "metadata": {},
   "source": [
    "<font size=5 > Predict the test dataset </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "51f0a393",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_lr = LogisticRegression()\n",
    "semi_model = SelfTrainingClassifier(new_lr, threshold = 0.6)\n",
    "semi_model.fit(semi_train_emb, semi_train_emb_label)\n",
    "semi_predict = semi_model.predict(test_emb)\n",
    "predict_result = pd.DataFrame(semi_predict)\n",
    "predict_result.to_csv('predict.csv', header = 'Category', index = 'Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5a100f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rfc_model = RandomForestClassifier(random_state=0)\n",
    "# semi_model_2 = SelfTrainingClassifier(rfc_model, threshold = 0.6)\n",
    "# semi_model_2.fit(semi_train_emb, semi_train_emb_label)\n",
    "# semi_predict_2 = semi_model_2.predict(test_emb)\n",
    "# predict_result_2 = pd.DataFrame(semi_predict_2)\n",
    "# predict_result_2.to_csv('predict_2.csv', header = 'Category', index = 'Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "d880881d",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_lr = LogisticRegression()\n",
    "semi_model = SelfTrainingClassifier(new_lr, threshold = 0.9)\n",
    "semi_model.fit(semi_train_emb, semi_train_emb_label)\n",
    "semi_predict = semi_model.predict(test_emb)\n",
    "predict_result = pd.DataFrame(semi_predict)\n",
    "predict_result.to_csv('predict_3.csv', header = 'Category', index = 'Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "3f7ab124",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_model_new = RandomForestClassifier(random_state=0)\n",
    "rfc_new = rfc_model_new.fit(train_emb, train_emb_label)\n",
    "rfc_predict_new = rfc_new.predict(test_emb)\n",
    "predict_result_7 = pd.DataFrame(rfc_predict_new)\n",
    "predict_result_7.to_csv('predict_7.csv', header = 'Category', index = 'Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "757f80d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_model = RandomForestClassifier(random_state=0)\n",
    "semi_model_3 = SelfTrainingClassifier(rfc_model, threshold = 0.9)\n",
    "semi_model_3.fit(semi_train_emb, semi_train_emb_label)\n",
    "semi_predict_3 = semi_model_3.predict(test_emb)\n",
    "predict_result_8 = pd.DataFrame(semi_predict_3)\n",
    "predict_result_8.to_csv('predict_8.csv', header = 'Category', index = 'Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e9d290",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
